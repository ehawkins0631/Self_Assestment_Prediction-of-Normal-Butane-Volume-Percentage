**Self Assestment Prediction of Normal Butane Volume Percentage**

1.- Self Assestment:

- With our project we wanted to explain:
    * How a machine learning algorithm is used in data analytics.
    * Create training and test groups from Normal-Butane-Volume-Percentage data set.
    * Implement the logistic regression, decision tree, random forest, and Support Vector Machine algorithms.
    * Interpret the results of the logistic regression, decision tree, random forest, and support vector machine algorithms.
    * Compare the advantages and disadvantages of each supervised learning algorithm.
    * Determine which Supervised Learning algorithm is best used for Normal-Butane-Volume-Percentage data set.
    * Use ensemble and resampling techniques to improve model performance.

- ETL:

We were able to create a function to extract, transform and load the three datasets. All three datasets were extracted into DataFrames correctly. The DataFrames were displayed and contained the correct columns. We cleaned Normal-Butane-Volume-Percentage data. We filtered out the Normal-Butane-Volume-Percentage, used try-except to drop duplicates. We list comprehension was used to drop columns with null values. The box values were converted correctly into strings. The budget, release date and running time were cleaned properly. Well done! On deliverable 3, the Kaggle data cleaning was tackled. Kaggle data was merged with data to form the Prediction-of-Normal-Butane-Volume-Percentage DataFrame. Unnecessary columns were dropped from this DataFrame, columns were renamed and missing Kaggle data was filled using Prediction-of-Normal-Butane-Volume-Percentage data. Normal-Butane-Volume-Percentage data was  cleaned and merged with the  Prediction-of-Normal-Butane-Volume-Percentage DataFrame. The empty rows were filled with zero. The DataFrames are displayed and have the correct columns.

- Web with HTML/CSS:

All of prediction-of-Normal-Butane-Volume-Percentage images, tables, code were correctly displayed, stored, and retrieved. The data is properly displayed using HTML and aesthetically enhanced through CSS and additional bootstrap 3 components. 

- Pandas:

We were able to cohesively present a written analysis that summarizes the data displayed in the dataframe and multiple-line chart. We also explained the implication of both analyses.  We created our DataFrames in our notebook. It cont ained all the prediction-of-Normal-Butane-Volume-Percentage. The notebook also generated a summary DataFrame with all the requirements. We were effectively able to demonstrate the graph with annotations, x-axis is by dates and the correct graph style is used. We comprehensive reports and how you used the data to support it

- Matplotlib:

We were able to cohesively present a written analysis that summarizes the data displayed in the dataframe and multiple-line chart! You also explained the implication of both analyses! Very nice report! Great job on creating your DataFrames in your notebook. It contained all the rides, drivers, fares and averages. Our notebook also generated a summary DataFrame with all the requirements. We were effectively able to demonstrate the graph with annotations, x-axis is by months and the correct graph style is used. 

- SQL:

We more than delivered on our query establishment that enabled us to create a table with unique Normal-Butane-Volume-Percentage tables â€“ all of which were correct and successfully exported as CSV files. We structured our written analysis, we make sure expand on all of the required touchpoints. In addition, the format of our findings were arranged accordingly: Furthermore, in our analysis we have a well-defined purpose. Moreover, our summary addresses tables and queries present as well.

Statistics:

We were able to demonstrate our statistics abilities with this project, we got a very marketable skill during this Bootcamp. The linear regression to predict Normal Butane Volume Percentage was great! We imported the csv file and read into a DataFrame. You wrote a clean R script for a linear regression model to perform on all our variables. An R script was also written well to create a statistical summary of the regression and it addresses all three questions!  The total summary has all the metrics. An R script was written for a t-test that compares Prediction of Normal Butane Volume Percentage Vs. Actual Real Time, an R script was also written for all three t-tests. We were able to address the results across all Prediction of Normal Butane Volume Percentage data set. We have an awesome statistical design. We had a metric to be tested, a null or alternate hypothesis was described, our statistical test is well described and the data for the statistical test is well described. This was an amazing project, we really got to showcase our R and statistical modeling knowledge in a beautiful comprehensive manner. We wish to keep up the good work and this amazing flow we have been able to establish for the next project.

Figure 1. Linear Regression

![image](https://user-images.githubusercontent.com/101227930/185302134-7e35ff5c-ce25-4316-9b91-4122aa869cc7.png)



Python: we proficiently implement python code and the correct pathing.

- Our Website: we were able to demonstrate our bar chart creation abilities. We created a title for the chart from the layout array. As soon as the web application is loaded up, the bar chart behaves exactly as it should.  We correctly displayed the dashboard at our webpage. All elements are created with the layout and when the webpage loads, we were able created a new environment with the necessary requirements in order to deploy Heroku,  our webpage is fully responsive and clean when the app loads. The webpage has all three customizations and loads and updated all the required tables and charts without any errors.

- Big Data:

Our notebook file set a Normal Butane Volume Percentage dataset and it is extracted as a DataFrame , then our extracted dataset is transformed into a DataFrames with the correct columns and all our DataFrames are loaded into their respective tables in pgAdmin. The data is filtered to create a DataFrame or table where there are 20 or more dates. The data is filtered to create a DataFrame or table where the  Prediction of Normal Butane Volume Percentage is equal to or greater than 50% . 

- Supervised Machine Learning:
We were able to demonstrate our machine learning abilities. When resampling models to Predict of Normal Butane Volume Percentage, there was an accuracy score and confusion matrix for all three algorithms. And, we were able to simultaneously generate a classification resort for all three respective algorithms, we did a great job in regards to predicting Normal Butane Volume Percentage for the SMOTEENN algorithm. There is a confusion matrix and classification report. We used ensemble classifier to predict Normal Butane Volume Percentage. Proper implementation of accuracy score and confusion matrix for one algorithms. We were able to create a classification report and for one algorithms. We were able to sorting our list features, as well. Our purpose is well defined. The balanced accuracy score and the precision and recall scores for all our algorithms are described. Additionally, in our project the results are summarized with a recommendation. 

- Feature Importances
We also went ahead and calculated some feature importances, feature coefficients, and correlations to understand the relationships of the features among each other and with different model types. The feature importance functions such as model.coef_ and model.feature_importances_, along with naitive process knowlege of team group members, allowed for a systematic ranking of features. Though 54 of the original 56 features were left in the model, the feature importance ranking is a valuable output and will be used to further tune the model outside of the class project end date.


-Unsupervised Machine Learning:

We were able to preprocess the data for Prediction of Normal Butane Volume Percentage. We were able to perform all the following requirements on the Normal Butane Volume Percentagecrypto_df DataFrame. All the information that we do not need longer are removed and the ones that do not have a defined algorithm are removed, all the ones with at least one null value are dropped..Also we created a new DataFrame that stores of Prediction of Normal Butane Volume Percentage. We have an optimal method in place to create variables for all the text features, and we were also able to store in a DataFrame. The features from the DataFrame have been standardized with the proper function. We were able to reduce data dimensions using PCA. Our PCA algorithm reduces dimensions of the X dataFrame to three principle components. We were able to create the Prediction of Normal Butane Volume Percentage DataFrame with the columns. Our DataFrame uses the index from our Prediction of Normal Butane Volume Percentage DataFrame. When it came to clustering our Prediction of Normal Butane Volume Percentageyour using K-means, we were able to establish an elbow curve using hvPlot to find the best value for K. Optimal predictions are made.A new DataFrame is created with the same index as our Prediction of Normal Butane Volume Percentage DataFrame and has the necessary columns. Finally, the clusters were well plotted using a 3-D scatter plot and each data point shows the respective information and algorithm associated with it upon hovering. We did great job visualizing and materializing our results. We were really excited with our first project. Money Saver Team is the best. Also we created a  table with our Prediction of Normal Butane Volume Percentages using a function, which is then printed. DataFrame is created containing all clustered respective data. This was a tough project and ourt team did an absolute stellar job.


Neural Networks and Deep Learning Models:

We were able to complete all the pre-processing steps for the Prediction of Normal Butane Volume Percentage dataset. WE dropped the unnecessary columns, grouped the categorical features and applied one hot encoding successfully. The data was split correctly into X/y and Training/test sets. We applyied  the standard scaler. Also we  implemented the neural network model using tensorflow. The parameters were set for the number of layers, number of neurons and the activation functions. The network structure was displayed as output. We also measured the accuracy and loss of the model correctly and this was displayed. Weights were saved but not every 5 epochs and the results were saved to a HDF 5 file. Two out of three attempts were made to optimize the model. We tried to apply several changes to the parameters of the model. Some layers and neurons were added.


2.- Group Assestment

We cohesively present our analysis and draw reasonable conclusion from our Normal-Butane-Volume-Percentage dataset:

In conclusion, there is certainly limitations to the model. While it does not predict the N-Butane Vol% exactly, it does seem to trend the general direction of the N-Butane Vol%, and generally predicts this figure within 2-5 Vol% points. By only allowing the prediction to occur when all input data streams are within normal operating conditions, performance is likly to improve.


3.- Summary of Project

Analysis Output Performance

Performance Metrics
The following performace metric results were gathered based on the X_test predictions.

Figure 2: Metrics 

![image](https://user-images.githubusercontent.com/101227930/185315649-69ecf9f0-c649-4a31-8407-277a975afd04.png)



Residual Plot: The plot in Figure 2 show evenly distributed residuals, thus giving reason to believe the model performs well and is not over-fit.
Figure 3: Residual Plot

![image](https://user-images.githubusercontent.com/101227930/185297754-189facfe-7a53-4692-80d8-6e8cbfc9ea06.png)


The total Mean Absolute Error is 1.92, meaning the average error is only 1.92 Vol%.
The total Root Mean Squared Error is 3.51
Absolute Deviation Accuracy: 84.3%
Total Deviation Accuracy: 99.4%

Real Time Model Performance
Finally, real time data, not included in the original dataset was taken from the past 3 weeks and ran in place of the X_test data as X_realtime data. Unfortunately, unit downtime during this time-span allowed only 4 days of continuous runtime data to be input. This real time data was input to the model to simulate an operators view of actual and simulated N-Butane Vol% in TA's recycle line. The results are shown in Figure 4 below.

Figure 4: Real Time Model Performance

![image](https://user-images.githubusercontent.com/101227930/185296714-bcfd6502-d606-4bbb-b380-967d5297828d.png)


Conclusion
In conclusion, there is certainly limitations to the model. While it does not predict the N-Butane Vol% exactly, it does seem to trend the general direction of the N-Butane Vol%, and generally predicts this figure within 2-5 Vol% points. By only allowing the prediction to occur when all input data streams are within normal operating conditions, performance is likly to improve.



